{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Imports and utilities</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class resBlock(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(resBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm1d(256)\n",
    "        self.relu1 = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv1d(256, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU(inplace=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu1(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out = out + x\n",
    "        out = self.relu2(out)\n",
    "        return out\n",
    "\n",
    "class PUFFIN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PUFFIN, self).__init__()\n",
    "        self.conv = nn.Conv1d(40, 256, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn = nn.BatchNorm1d(256)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.resBlocks = nn.Sequential(*[resBlock() for i in range(5)])\n",
    "        self.avgpool = nn.AvgPool1d(9, stride = 1, padding = 0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.relu(self.bn(self.conv(x)))\n",
    "        out = self.resBlocks(out)\n",
    "        out = self.avgpool(out).view((-1, 256))\n",
    "        return out\n",
    "    \n",
    "class GaussianPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GaussianPredictor, self).__init__()\n",
    "        self.embed = PUFFIN()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.extractMean = nn.Linear(256, 1)\n",
    "        self.extractStd = nn.Linear(256, 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.embed(x)\n",
    "        noisy_embedding = self.dropout(embedding)\n",
    "        \n",
    "        mean = self.extractMean(noisy_embedding)\n",
    "        std = F.softplus(self.extractStd(noisy_embedding))\n",
    "        return mean, std\n",
    "    \n",
    "class CategoricalPredictor(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CategoricalPredictor, self).__init__()\n",
    "        self.embed = PUFFIN()\n",
    "        self.dropout = nn.Dropout(0.2)\n",
    "        \n",
    "        self.extractCategory = nn.Linear(256, 8)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        embedding = self.embed(x)\n",
    "        noisy_embedding = self.dropout(embedding)\n",
    "        \n",
    "        dist = F.softmax(self.extractCategory(noisy_embedding), dim = 1)\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_categorical_model(allele, split, initialization):\n",
    "    fn = \"./models/Categorical_DR40{}_split{}_init{}.pt\".format(allele, split, initialization)\n",
    "    model = CategoricalPredictor()\n",
    "    model.load_state_dict(torch.load(fn))\n",
    "    model.eval()\n",
    "    model.dropout.train()\n",
    "    return model\n",
    "\n",
    "def load_gaussian_model(allele, split, initialization):\n",
    "    fn = \"./models/Gaussian_DR40{}_split{}_init{}.pt\".format(allele, split, initialization)\n",
    "    model = GaussianPredictor()\n",
    "    model.load_state_dict(torch.load(fn))\n",
    "    model.eval()\n",
    "    model.dropout.train()\n",
    "    return model\n",
    "\n",
    "def runCategoricalEnsemble(ens, x):\n",
    "    with torch.no_grad():\n",
    "        exm1 = torch.tensor( [float(i) for i in range(8)] ).cuda()\n",
    "        exm2 = torch.tensor( [float(i**2) for i in range(8)] ).cuda()\n",
    "        mns = []\n",
    "        vrs = torch.zeros((x.size(0),1)).cuda()\n",
    "        for model in ens:\n",
    "            for i in range(50):\n",
    "                out = model(x)\n",
    "                mom1 = torch.sum(out*exm1, dim = 1).view((-1,1))\n",
    "                mom2 = torch.sum(out*exm2, dim = 1).view((-1,1))\n",
    "                mns.append( mom1 )\n",
    "                vrs = vrs + mom2 - (mom1**2)\n",
    "        mns = torch.cat(mns, dim = 1)\n",
    "        vrs = ( (vrs/1000).view(-1) + torch.var(mns, dim = 1, unbiased=False) ).cpu().numpy()\n",
    "        mns = torch.mean(mns, dim = 1).cpu().numpy()\n",
    "    return mns, vrs\n",
    "\n",
    "def runGaussianEnsemble(ens, x):\n",
    "    with torch.no_grad():\n",
    "        mns = []\n",
    "        vrs = torch.zeros((x.size(0),1)).cuda()\n",
    "        for model in ens:\n",
    "            for i in range(50):\n",
    "                mean,std = model(x)\n",
    "                mns.append( mean )\n",
    "                vrs = vrs + (std ** 2)\n",
    "        mns = torch.cat(mns, dim = 1)\n",
    "        vrs = ( (vrs/1000).view(-1) + torch.var(mns, dim = 1, unbiased=False) ).cpu().numpy()\n",
    "        mns = torch.mean(mns, dim = 1).cpu().numpy()\n",
    "    return mns, vrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Running PUFFIN and generating anchor substitutions</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These functions load the ensembles and the functions for running them\n",
    "\n",
    "def getEnsemble_Categorical(allele):\n",
    "    ens = []\n",
    "    for split in range(1,11):\n",
    "        for i in (1,2):\n",
    "            model = load_categorical_model(allele, split, i).cuda()\n",
    "            ens.append(model)\n",
    "    return ens, runCategoricalEnsemble\n",
    "\n",
    "def getEnsemble_Gaussian(allele):\n",
    "    ens = []\n",
    "    for split in range(1,11):\n",
    "        for i in (1,2):\n",
    "            model = load_gaussian_model(allele, split, i).cuda()\n",
    "            ens.append(model)\n",
    "    return ens, runGaussianEnsemble\n",
    "\n",
    "# Get Categorical predictor for DR401\n",
    "#getEnsemble_Categorical(1)\n",
    "# Get Categorical predictor for DR402\n",
    "#getEnsemble_Categorical(2)\n",
    "# Get Gaussian predictor for DR401\n",
    "#getEnsemble_Gaussian(1)\n",
    "# Get Gaussian predictor for DR402\n",
    "#getEnsemble_Gaussian(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# embed will embed the required function\n",
    "\n",
    "aaEmbedding = {}\n",
    "with open(\"./aa_embedding.txt\", 'rt') as fin:\n",
    "    for line in fin:\n",
    "        line = line.rstrip('\\n').split(',')\n",
    "        aaEmbedding[line[0]] = tuple( [float(z) for z in line[1:]] )\n",
    "        \n",
    "def embed(seqs):\n",
    "    embedded = []\n",
    "    for seq in seqs:\n",
    "        embedded.append(torch.tensor([aaEmbedding[c] for c in seq]).permute(1,0))\n",
    "    return embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of how to run PUFFIN\n",
    "def example_use():\n",
    "    # Embed sequences as into a batch of tensors\n",
    "    t = torch.stack(embed([\"QMCPGDGRP\", \"FRVSSTLQA\"])).cuda()\n",
    "    \n",
    "    # Load ensemble and function for running them\n",
    "    ens, run_ens = getEnsemble_Categorical(1)\n",
    "    \n",
    "    # Run ensemble on sequences\n",
    "    mean, var = run_ens(ens, t)\n",
    "    print (\"Mean: {}\\nVar: {}\".format(mean, var))\n",
    "    \n",
    "# Run this to test if we can load the ensemble and run predictions\n",
    "#example_use()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateLandscape(s):\n",
    "    aa = \"ACDEFGHIKLMNPQRSTVWY\"\n",
    "    substitutions = []\n",
    "    for aa1 in aa:\n",
    "        for aa2 in aa:\n",
    "            for aa3 in aa:\n",
    "                for aa4 in aa:\n",
    "                    substitutions.append( aa1 + s[1:3] + aa2 + s[4:5] + aa3 + s[6:8] + aa4 )\n",
    "    return substitutions\n",
    "\n",
    "# Generate proposals (PE)\n",
    "def propose_subst_PE(seq, ensemble, batch_size = 100):\n",
    "    ens, run_f = ensemble\n",
    "    subst = generateLandscape(seq)\n",
    "    i = 0\n",
    "    means = []\n",
    "    while i < len(subst):\n",
    "        emb = torch.stack(embed( subst[i: i+batch_size] )).cuda()\n",
    "        mns, _ = run_f(ens, emb)\n",
    "        means.append(mns)\n",
    "        i += batch_size\n",
    "        print (\"Progress: {}/160000\".format(i))\n",
    "    scores = np.concatenate(means)\n",
    "    best = np.argsort(-scores)\n",
    "    proposals = [subst[j] for j in best[:11]]\n",
    "    if seq in proposals:\n",
    "        proposals.remove(seq)\n",
    "    return proposals[:10]\n",
    "    \n",
    "# Generate proposals (UCB)\n",
    "def propose_subst_UCB(seq, ensemble, batch_size = 100):\n",
    "    ens, run_f = ensemble\n",
    "    subst = generateLandscape(seq)\n",
    "    i = 0\n",
    "    means = []\n",
    "    variances = []\n",
    "    while i < len(subst):\n",
    "        emb = torch.stack(embed( subst[i: i+batch_size] )).cuda()\n",
    "        mns, vrs = run_f(ens, emb)\n",
    "        means.append(mns)\n",
    "        variances.append(vrs)\n",
    "        i += batch_size\n",
    "        print (\"Progress: {}/160000\".format(i))\n",
    "    scores = np.concatenate(means) + np.sqrt(np.concatenate(variances))\n",
    "    best = np.argsort(-scores)\n",
    "    proposals = [subst[j] for j in best[:11]]\n",
    "    if seq in proposals:\n",
    "        proposals.remove(seq)\n",
    "    return proposals[:10]    \n",
    "\n",
    "# Example: generate anchor substitutions for QMCPGDGRP that optimize for DR401 binding using the Gaussian model\n",
    "# Adjust batch_size to address memory limitations/runtime\n",
    "#propose_subst_UCB(\"QMCPGDGRP\", getEnsemble_Gaussian(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
